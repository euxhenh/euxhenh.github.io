<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="iiue3lbbbvQyZBEZ9SlxWP9yHa6y3RL-l87D7GnWFno"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Illusion of Reasoning Benchmarks | Euxhen Hasanaj </title> <meta name="author" content="Euxhen Hasanaj"> <meta name="description" content="A response to " the illusion of thinking> <meta name="keywords" content="euxhen hasanaj"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://euxhenh.github.io/blog/2025/illusion-reasoning-benchmarks/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="//"> <span class="font-weight-bold">Euxhen</span> Hasanaj </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/CV_EH.pdf">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Illusion of Reasoning Benchmarks</h1> <p class="post-meta"> Created in June 29, 2025 </p> <p class="post-tags"> <a href="//blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="//blog/tag/llms"> <i class="fa-solid fa-hashtag fa-sm"></i> LLMs</a>   <a href="//blog/tag/reasoning"> <i class="fa-solid fa-hashtag fa-sm"></i> reasoning</a>   <a href="//blog/tag/benchmark"> <i class="fa-solid fa-hashtag fa-sm"></i> benchmark</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>In <a href="https://machinelearning.apple.com/research/illusion-of-thinking" rel="external nofollow noopener" target="_blank"><em>The Illusion of Thinking</em></a> (Shojaee et al., 2025), the authors investigate whether LLMs truly exhibit reasoning capabilities. Using controlled puzzle environments like the Tower of Hanoi, Blocks World, and River Crossing, they systematically vary problem complexity and analyze both final answers and the intermediate reasoning steps (or “thought traces”) of several LLMs and LRMs. For example, the River Crossing problem is defined as (Shoajaee et al. 2025):</p> <blockquote style="font-size: 1em;"> River Crossing is a constraint satisfaction planning puzzle involving <strong>n</strong> actors and their corresponding <strong>n</strong> agents who must cross a river using a boat. The goal is to transport all <strong>2n</strong> individuals from the left bank to the right bank. The boat can carry at most <strong>k</strong> individuals and cannot travel empty. Invalid situations arise when an actor is in the presence of another agent without their own agent present, as each agent must protect their client from competing agents. </blockquote> <p>Their findings show that while reasoning models can outperform standard LLMs on moderately complex tasks, both types collapse when facing higher complexity. The models not only fail to generate correct final answers but also reduce the number of tokens spent thinking, despite having ample inference budget. The authors conclude that these models do not possess robust, generalizable reasoning abilities and often resort to pattern matching or heuristics.</p> <p>This evaluation paradigm has a critical limitation: <em>it equates reasoning with successful execution on large-scale planning tasks</em>. In reality, even humans rarely attempt to fully <em>execute</em> high-complexity problems (like the 20-disk Tower of Hanoi). They describe a recursive <em>strategy</em> and, if needed, prove its correctness. Reasoning should not be judged solely by whether an agent can follow through every step, but by whether it can understand and articulate a generalizable plan.</p> <p>Reasoning is about <strong>forming mental models and generalizing patterns</strong>, not brute-force enumeration. There’s a distinction between <em>declarative knowledge</em> (“I know how it works”) and <em>procedural knowledge</em> (“I can carry it out”). Models may exhibit the former without the latter. Yet even within declarative reasoning, there is plenty of meaningful cognitive work that can occur, identifying structure, articulating valid solution paths, proving why a certain approach works, or recognizing edge cases and constraints. These are core components of intelligent reasoning, and evaluating them provides richer insights into a model’s capabilities than simply measuring whether it can follow through every step of an execution-heavy task.</p> <p>Current puzzle-based benchmarks (like in the paper) measure step-by-step <strong>correctness</strong> under token limits and planning bandwidth. This punishes models for lack of <em>execution capacity</em>, not for lack of <em>strategic insight</em>. A better test of reasoning would focus on whether a model can generalize rules, derive patterns, or prove properties whose complexity scales with the problem. For example, logical inference tasks (“Given a set of rules and premises, what follows?”) become progressively harder as the rule set grows deeper or more entangled. Similarly, problems like “prove that the number of ways to tile a 2×n grid with dominoes is the nth Fibonacci number” require models to identify recurrences, construct generalizations, and articulate inductive reasoning, none of which require executing each instance. These tests move away from mere simulation and toward the kind of scalable symbolic abstraction that more closely mirrors human reasoning.</p> <p>In sum, the collapse of LLM performance on highly complex procedural puzzles may say more about their execution limits than their reasoning potential. If we want to understand whether LLMs can reason, we must move beyond testing their ability to follow steps and toward testing their ability to generate, explain, and generalize <em>strategies</em>. Reasoning is not about grinding through complexity, it’s about seeing through it. Until benchmarks evolve to reflect this, we risk underestimating what LLMs already do well, and misunderstanding what reasoning truly requires.</p> <h4 id="references">References</h4> <p>[1] Shojaee, P. <em>et al.</em> The illusion of thinking: Understanding the strengths and limitations of reasoning models via the lens of problem complexity. <em>arXiv [cs.AI]</em> (2025).</p> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Euxhen Hasanaj. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: June 29, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-8KTM7BQY99"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-8KTM7BQY99");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>